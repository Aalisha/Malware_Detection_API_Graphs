import numpy as np
import sknn
from sknn.mlp import Layer
from sknn.mlp import Classifier
import pandas as pd
import warnings
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
import time
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedShuffleSplit
from theano.tensor.signal.pool import pool_2d
from sklearn.metrics import classification_report
from sklearn.preprocessing import MinMaxScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_auc_score
from sklearn.metrics import make_scorer


warnings.filterwarnings("ignore", category=DeprecationWarning)




file="data.csv";

data=pd.read_csv(file);
train=data.drop(['Unnamed: 0','label'],axis=1);
target=data['label'];
X=train.values;
y=target.values;
sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=0)
sss.get_n_splits(X, y);

for train_index, test_index in sss.split(X, y):
	print("TRAIN:", train_index, "TEST:", test_index)
	X_train, X_test = X[train_index], X[test_index]
	y_train, y_test = y[train_index], y[test_index]

scaler = MinMaxScaler();
scaler.fit(X_train);
X_train=scaler.transform(X_train);
X_test=scaler.transform(X_test);

#MLP
print "MLP"
w_train = np.empty((y_train.shape[0],))
w_train[y_train == 0] = 0.9
w_train[y_train == 1] = 2.1

layers=[Layer(type='Tanh',units=7,dropout=0.25),Layer(type='Softmax')];
nn = Classifier(layers,valid_set=None,valid_size=0,batch_size=10,n_stable=20, n_iter=100,learning_rule='sgd',learning_rate=0.05,verbose=True);
nn.fit(X_train, y_train,w_train)
#nn.fit(X_train, y_train)
print "Training score"
print nn.score(X_train,y_train);
y_test_pred=nn.predict(X_test);
#Training Accuracy
y_pred=nn.predict(X_train)
print "Classification report train"
print classification_report(y_train,y_pred)
print "Score"
print nn.score(X_train,y_train);
print "Classification Report test"
print classification_report(y_test,y_test_pred)


print "Test Score"
print nn.score(X_test,y_test);

print "Test confusion matrix"
print confusion_matrix(y_test,y_test_pred)

auc=roc_auc_score(y_test, y_test_pred)

print "test auc"
print auc



'''Grid Search to find optimal parameter values'''
'''
params={'algorithm': 'sgd', 'learning_rate': 'invscaling'}
layers=[Layer(type='Tanh',units=7,dropout=0.25),Layer(type='Softmax')];
nn = Classifier(layers,valid_set=None,valid_size=0, n_iter=50,learning_rule='sgd',learning_rate=0.05);

pipeline = Pipeline([
        ('min_max_scaler', MinMaxScaler(feature_range=(0.0, 1.0))),
        ('neural_network', nn)])

print "Start time"
start=time.time()
print start

X_train=np.array(X_train);
y_train=np.array(y_train);
start=time.time()
param = dict(neural_network__learning_rate=[0.05, 0.01, 0.005, 0.001], neural_network__hidden0__type=["Rectifier", "Sigmoid", "Tanh"],
              neural_network__hidden0__units=[2, 3, 4, 5, 7])


cv = GridSearchCV(pipeline, param_grid=param)

cv.fit(X_train, y_train)

print "End time"

print time.time()-start

print cv.grid_scores_
print cv.best_estimator_
print cv.best_params_
'''
